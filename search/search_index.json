{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"WSMP Tech Docs","text":"<p>WSMP (Warp Speed Message Protocol) is a lightweight, UDP-based protocol for fast, reliable messaging between services on high-quality networks (VPC, LAN). It targets payloads up to 64 KB and prioritizes low latency and efficient batching over heavyweight transport features. The reference implementation is built in Rust.</p>"},{"location":"#why-wsmp-motivation-and-advantages-over-http2-and-quic","title":"Why WSMP: Motivation and Advantages over HTTP/2 and QUIC","text":"<p>WSMP was designed to optimize the transmission of small messages in trusted high-speed networks, where traditional protocols like HTTP/2 and QUIC introduce unnecessary overhead, particularly in high-throughput scenarios. Here are the key reasons for creating the protocol:</p> <ul> <li>Reduced latency for small requests through simplified flow control: both HTTP/2 (over TCP) and QUIC (HTTP/3) use strict credit-based flow control mechanisms. The receiver must actively send WINDOW_UPDATE or MAX_DATA frames to allow the sender to continue transmitting, introducing additional RTT for signaling. In scenarios involving small messages (1\u201310 KB) at high throughput (thousands of requests per second), this causes latency spikes as the sender may stall waiting for window updates despite available bandwidth. WSMP employs an advisory-driven approach: the receiver only suggests missing fragments or recommends a window size, without mandatory blocking. This eliminates unnecessary signaling overhead and latency, making the protocol ideal for internal microservice communications in data centers or VPCs, where the network is stable and congestion is minimal.</li> <li>Avoiding unnecessary congestion control in controlled environments: QUIC and HTTP/2 incorporate built-in congestion control mechanisms (similar to TCP), which are essential in WAN environments with variable latency and loss. In trusted high-speed networks (for example, AWS VPC or on-premises clusters), these mechanisms add superfluous probing and backoff delays that reduce throughput. WSMP relies on sender-driven retries without global congestion signaling, enabling maximum performance without over-engineering.</li> <li>Lower overall overhead for tiny payloads: encryption and framing in QUIC/HTTP/2 (with per-packet crypto and multiplexing) increase CPU load and packet size, becoming a bottleneck at speeds over 1 Gbps. WSMP minimizes header size (8\u201316 bytes baseline) and supports message batching, delivering better p99 latency and throughput in scenarios like in-cluster messaging in Kubernetes.</li> </ul> <p>In summary, WSMP is a targeted alternative for niche use cases where the universality of HTTP/2 and QUIC becomes a performance liability. Benchmarks against gRPC or raw HTTP/2 in low-latency environments are recommended to quantify these advantages.</p>"},{"location":"#design-goals","title":"Design goals","text":"<ul> <li>Small payloads: up to 64 KB per message.</li> <li>Fast, reliable delivery inside a trusted network domain.</li> <li>Efficient batching via <code>sendmmsg</code>/<code>recvmmsg</code> and GSO/GRO.</li> <li>Minimal protocol overhead with explicit flow control.</li> <li>Lightweight like UDP-DNS, but suitable for generic payloads.</li> </ul>"},{"location":"#protocol-overview","title":"Protocol overview","text":"<p>WSMP has two layers: an encryption layer and a payload layer. The encryption layer establishes a secure session with a TLS-like handshake, while the payload layer carries application messages.</p> <ul> <li>Transport: UDP with a custom encryption layer and a TLS-like handshake.</li> <li>Messaging model: request-response, with association via client-generated <code>message_id</code>.</li> <li>Reliability: sender-driven retries when delivery is missing; receiver may advise missing pieces during defragmentation. The client defines retry count and backoff strategy, yielding at-least-once delivery semantics.</li> <li>Flow control: advisor-driven rather than aggressive window management.</li> <li>Session recovery: receiver can send an advisory packet to re-establish a session when it sees an expired or unknown session (for example, after load-balancer re-routing).</li> <li>Keepalive: ping/pong advisory packets for liveness checks and latency sampling.</li> </ul>"},{"location":"#handshake-packet-format-suggested","title":"Handshake packet format (suggested)","text":"<p>The handshake is TLS/DTLS-inspired but transported over WSMP's own UDP record layer.</p> <p>Record header:</p> <pre><code>+---------+------------+-------+-----------------+--------+\n| version | record_type| epoch | sequence_number | length |\n+---------+------------+-------+-----------------+--------+\n| 1 byte  | 1 byte     | 1 byte| 4 bytes         | 2 bytes|\n</code></pre> <p>Handshake fragment (DTLS-style):</p> <pre><code>+--------+-----------+------------+------------------+-----------------+\n| hs_type| hs_length | hs_msg_seq | fragment_offset  | fragment_length |\n+--------+-----------+------------+------------------+-----------------+\n| 1 byte | 3 bytes   | 2 bytes    | 3 bytes          | 3 bytes         |\n</code></pre> <p>Handshake message bodies (minimal):</p> <pre><code>ClientHello:\n+---------------+--------------------+------------------+------------+\n| client_random | session_id_hint    | cipher_suites    | extensions |\n| 32 bytes      | optional           | list             | list       |\n\nServerHello:\n+---------------+------------------+-----------------------+------------+\n| server_random | session_id       | cipher_suite_selected | extensions |\n| 32 bytes      | 8 or 16 bytes    |                       | list       |\n\nKeyExchange (optional):\n+-----------+----------------------+\n| key_share | signature (optional) |\n| X25519    | server-auth          |\n\nFinished:\n+-------------+\n| verify_data |\n</code></pre>"},{"location":"#message-format-and-framing","title":"Message format and framing","text":"<ul> <li>Encrypted payload is built from the handshaked session ID and the encrypted content (typically with a nonce) using AES-256-GCM.</li> <li>Encrypted payload size must not exceed 64 KB.</li> <li>Payload is split into datagram-sized frames; each frame includes its index and the total frame count.</li> <li>Frames match standard MTU sizes (for example, 1400 bytes) and are prefixed with their size to simplify GRO-based decoding.</li> <li>The last frame should be padded to the configured size to improve GRO coalescing; the size prefix preserves the true payload length with minimal overhead.</li> <li>Receiver buffers frames, reassembles once all are present, then decrypts.</li> <li>Decrypted payload layout: message <code>type</code> (data or advisory), then <code>message_id</code>, followed by the message content to the end of the buffer.</li> </ul>"},{"location":"#packet-and-payload-layout-ascii","title":"Packet and payload layout (ASCII)","text":"<p>Encrypted payload (before framing):</p> <pre><code>+------------------+--------------------------+\n| session_id (S)   | AES-256-GCM ciphertext   |\n|                  | (nonce + encrypted data) |\n+------------------+--------------------------+\n&lt;= 64 KB total\n</code></pre> <p>Frame (one UDP datagram):</p> <pre><code>+--------------+-----------+-------------+----------------------+\n| frame_size   | frame_id  | frame_count | encrypted_payload[..]|\n+--------------+-----------+-------------+----------------------+\nfits MTU (e.g. ~1400 bytes)\n</code></pre> <p>Decrypted payload (after reassembly and decryption):</p> <pre><code>+----------+-------------+-------------------+\n| type     | message_id  | message_content   |\n| (data/   |             | (rest of buffer)  |\n| advisory)|             |                   |\n+----------+-------------+-------------------+\n</code></pre>"},{"location":"#performance-features","title":"Performance features","text":"<ul> <li>Message collection and short-term batching to amortize syscalls.</li> <li>GSO buffer usage for efficient packetization.</li> <li>GRO-enabled receive paths for fast coalescing on ingress.</li> </ul>"}]}